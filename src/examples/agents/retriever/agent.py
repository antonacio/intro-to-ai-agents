from langchain_core.language_models import BaseLanguageModel
from langchain_core.documents import Document
from langgraph.graph import END, START, StateGraph
from langgraph.types import Send
from typing_extensions import Annotated
from pydantic import BaseModel, Field
from langchain_chroma import Chroma
from operator import add

from examples.agents.base_agent import BaseAgent
from examples.agents.retriever.prompts import GENERATE_QUERIES_SYSTEM_PROMPT
from examples.config import (
    vector_store_collection_name,
    embedding_model,
    vector_store_client,
)


class SingleQueryState(BaseModel):
    """Private state for each of the query_documents nodes running in parallel."""

    query: str = Field(
        description="The query used to retrieve documents from the vector store."
    )


class InputState(BaseModel):
    """Input state for the Retriever agent graph."""

    research_task: str = Field(
        description="A step in the overarching research plan generated by the ResearchAgent."
    )


class RetrieverState(BaseModel):
    """State for the Retriever agent graph."""

    research_task: str = Field(
        description="A step in the overarching research plan generated by the ResearchAgent."
    )
    search_queries: list[str] = Field(
        default=[],
        description="A list of search queries to retrieve documents from the vector store in order to answer the research task.",
    )
    retrieved_chunks: Annotated[list[Document], add] = Field(
        default=[],
        description="A list of retrieved document chunks from the vector store.",
    )


class RetrieverAgent(BaseAgent):
    """Retriever agent that generates search queries and retrieves documents from the vector store."""

    def __init__(
        self,
        llm: BaseLanguageModel,
        generate_queries_system_prompt: str = GENERATE_QUERIES_SYSTEM_PROMPT,
        **kwargs,
    ):
        """Initialize the Retriever agent.

        Args:
            llm: The language model to use.
            generate_queries_system_prompt: System prompt for the generate_queries node.
            **kwargs: Additional keyword arguments for the base agent initialization.
        """
        super().__init__(llm=llm, **kwargs)
        self._generate_queries_system_prompt = generate_queries_system_prompt
        # instantiate the vector store to retrieve documents from
        self._vector_store = Chroma(
            client=vector_store_client,
            collection_name=vector_store_collection_name,
            collection_metadata=vector_store_client.get_or_create_collection(
                vector_store_collection_name
            ).metadata,
            embedding_function=embedding_model,
        )

    def build_graph(self) -> StateGraph:
        """Build the Retriever agent graph."""

        async def generate_queries(state: InputState) -> RetrieverState:
            """Generate search queries based on the research task (a step in the research plan)."""

            class GeneratedQueries(BaseModel):
                queries: list[str] = Field(
                    description="A list of search queries to retrieve documents from the vector store."
                )

            generate_queries_prompt = self._generate_queries_system_prompt.format(
                research_task=state.research_task
            )
            generated_queries = await self.llm.with_structured_output(
                GeneratedQueries
            ).ainvoke(generate_queries_prompt)

            return {"search_queries": generated_queries.queries}

        async def query_documents(state: SingleQueryState) -> RetrieverState:
            """Retrieve information from documents based on a given search query."""

            # retrieve documents from the vector store with max marginal relevance
            retriever = self._vector_store.as_retriever(
                search_type="mmr",
                search_kwargs={"k": 2, "fetch_k": 5},
            )
            retrieved_chunks = await retriever.ainvoke(state.query)

            return {"retrieved_chunks": retrieved_chunks}

        def initialize_parallel_retrieval(state: RetrieverState) -> list[Send]:
            """Creates parallel retrieval tasks for each generated query."""
            return [
                Send("query_documents", SingleQueryState(query=query))
                for query in state.search_queries
            ]

        # Define the graph
        retriever_graph = StateGraph(
            input_schema=InputState, state_schema=RetrieverState
        )
        retriever_graph.add_node("generate_queries", generate_queries)
        retriever_graph.add_node("query_documents", query_documents)

        retriever_graph.add_edge(START, "generate_queries")
        retriever_graph.add_conditional_edges(
            "generate_queries",
            initialize_parallel_retrieval,
            ["query_documents"],
        )
        retriever_graph.add_edge("query_documents", END)

        return retriever_graph
