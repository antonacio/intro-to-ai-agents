{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b78efe2d",
   "metadata": {},
   "source": [
    "# ReAct Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b10f58",
   "metadata": {},
   "source": [
    "In this notebook we will build a [ReAct](https://react-lm.github.io/) agent, a general tool-calling agent architecture that:\n",
    "- lets the model call specific tools\n",
    "- passes the tool output back to the model\n",
    "- lets the model reason about the tool output to decide what to do next (e.g., call another tool or just respond directly)\n",
    "\n",
    "This [general purpose architecture](https://blog.langchain.dev/planning-for-agents/) can be applied to many types of tools. \n",
    "\n",
    "![ReAct architecture](https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F06f2cf46-df40-48f9-a798-931222b0f70a_590x592.png)\n",
    "\n",
    "The complete implementation of the ReAct agent can be found on `src/hackathon/agents/react/agent.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1367c28c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the environment variables\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5a5f34",
   "metadata": {},
   "source": [
    "## State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34964478",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from typing import Annotated, Any\n",
    "from operator import add\n",
    "from langchain_core.messages import AnyMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "# define the state\n",
    "class ReActState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]  # same as in langgraph.graph.MessagesState"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684f78b2",
   "metadata": {},
   "source": [
    "## Tools\n",
    "\n",
    "Here we define the tools using the `@tool` decorator. We set `response_format=\"content_and_artifact\"` to save the artifacts of a tool's execution that we want to make accessible to downstream components of the graph or backend APIs. \"For example if a tool returns a custom object, a dataframe or an image, we may want to pass some metadata about this output to the model without passing the actual output to the model. At the same time, we may want to be able to access this full output elsewhere, for example in downstream tools.\" ([see docs](https://python.langchain.com/docs/how_to/tool_artifacts/))\n",
    "\n",
    "This way, we distinguish between the parts of the tool output meant for the model (this is the ToolMessage.content) and those parts which are meant for use outside the model (ToolMessage.artifact)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca9f8643",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from hackathon.config import llm, ModelProviders\n",
    "\n",
    "@tool(response_format=\"content_and_artifact\", parse_docstring=True)\n",
    "def add(a: int, b: int) -> tuple[str, int]:\n",
    "    \"\"\"Adds a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    result = a + b\n",
    "    message = f\"Adding {a} and {b} gives {result}\"\n",
    "    return message, result\n",
    "\n",
    "@tool(response_format=\"content_and_artifact\", parse_docstring=True)\n",
    "def multiply(a: int, b: int) -> tuple[str, int]:\n",
    "    \"\"\"Multiply a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    result = a * b\n",
    "    message = f\"Multiplying {a} and {b} gives {result}\"\n",
    "    return message, result\n",
    "\n",
    "@tool(response_format=\"content_and_artifact\", parse_docstring=True)\n",
    "def divide(a: int, b: int) -> tuple[str, float]:\n",
    "    \"\"\"Divide a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    if b == 0:\n",
    "        raise ValueError(\"Cannot divide by zero\")\n",
    "    result = a / b\n",
    "    message = f\"Dividing {a} by {b} gives {result}\"\n",
    "    return message, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1a220d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [add, multiply, divide]\n",
    "\n",
    "if os.getenv(\"MODEL_PROVIDER\") == ModelProviders.OPENAI:\n",
    "    # we set parallel tool calling to false as math generally is done sequentially\n",
    "    bind_math_tools_kwargs = {\"parallel_tool_calls\": False}\n",
    "else:\n",
    "    # Ollama chat model does not support the parallel tool calling feature\n",
    "    bind_math_tools_kwargs = {}\n",
    "\n",
    "# Bind tools to the LLM\n",
    "llm_with_tools = llm.bind_tools(tools, **bind_math_tools_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a18817",
   "metadata": {},
   "source": [
    "## ReAct agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81deb700",
   "metadata": {},
   "source": [
    "### Nodes\n",
    "\n",
    "[`ToolNode`](https://langchain-ai.github.io/langgraph/reference/agents/#langgraph.prebuilt.tool_node.ToolNode) is a useful shortcut if you want to create a node to execute tools.\n",
    "\n",
    "The `ToolNode` is roughly analogous to:\n",
    "\n",
    "```python\n",
    "tools_by_name = {tool.name: tool for tool in tools}\n",
    "def tool_node(state: dict):\n",
    "    result = []\n",
    "    for tool_call in state[\"messages\"][-1].tool_calls:\n",
    "        tool = tools_by_name[tool_call[\"name\"]]\n",
    "        observation = tool.invoke(tool_call[\"args\"])\n",
    "        result.append(ToolMessage(content=observation, tool_call_id=tool_call[\"id\"]))\n",
    "    return {\"messages\": result}\n",
    "```\n",
    "\n",
    "the [`tools_condition`](https://langchain-ai.github.io/langgraph/reference/agents/#langgraph.prebuilt.tool_node.tools_condition) is a simple router used to build the ReAct's conditional edge:\n",
    "- If the latest message from assistant is a tool call -> tools_condition routes to `\"tools\"` (we need to make sure to name the tool node as `\"tools\"`)\n",
    "- If the latest message from assistant is a not a tool call -> tools_condition routes to `END`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56018a47",
   "metadata": {},
   "source": [
    "### Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae9cfea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, END, StateGraph\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage, ToolMessage\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# System message\n",
    "sys_msg = SystemMessage(content=\"You are a helpful assistant tasked with performing arithmetic on a set of inputs.\")\n",
    "\n",
    "# Nodes\n",
    "def llm_node(state: ReActState):\n",
    "   return {\"messages\": [llm_with_tools.invoke([sys_msg] + state[\"messages\"])]}\n",
    "\n",
    "tool_node = ToolNode(tools)\n",
    "\n",
    "# Graph\n",
    "react_builder = StateGraph(ReActState)\n",
    "\n",
    "# Define nodes\n",
    "react_builder.add_node(\"llm\", llm_node)\n",
    "react_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "# Define edges\n",
    "react_builder.add_edge(START, \"llm\")\n",
    "react_builder.add_conditional_edges(\"llm\", tools_condition)  # routes to \"tools\" or \"__end__\"\n",
    "react_builder.add_edge(\"tools\", \"llm\")\n",
    "\n",
    "# Compile the graph\n",
    "react_graph = react_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08efc4f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show Graph\n",
    "display(Image(react_graph.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b98c300",
   "metadata": {},
   "source": [
    "### Run ReAct Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f2a9b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input\n",
    "messages = [\n",
    "    HumanMessage(content=\"Add 11 and 53. Multiply the output by 2. Then divide it by 16\"),\n",
    "]\n",
    "\n",
    "# Run the graph\n",
    "react_output = react_graph.invoke(input={\"messages\": messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb0f332d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Add 11 and 53. Multiply the output by 2. Then divide it by 16\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  add (call_rSHI6ZW1ETy4YXFI7f3QRyjY)\n",
      " Call ID: call_rSHI6ZW1ETy4YXFI7f3QRyjY\n",
      "  Args:\n",
      "    a: 11\n",
      "    b: 53\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: add\n",
      "\n",
      "Adding 11 and 53 gives 64\n",
      "\n",
      " --> Tool artifact: 64 (type: <class 'int'>)\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (call_MZtbJwdrNGcMMa1aku3Hc1Mn)\n",
      " Call ID: call_MZtbJwdrNGcMMa1aku3Hc1Mn\n",
      "  Args:\n",
      "    a: 64\n",
      "    b: 2\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "Multiplying 64 and 2 gives 128\n",
      "\n",
      " --> Tool artifact: 128 (type: <class 'int'>)\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  divide (call_CMMhyRUb11Vzy6ep5YdFesle)\n",
      " Call ID: call_CMMhyRUb11Vzy6ep5YdFesle\n",
      "  Args:\n",
      "    a: 128\n",
      "    b: 16\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: divide\n",
      "\n",
      "Dividing 128 by 16 gives 8.0\n",
      "\n",
      " --> Tool artifact: 8.0 (type: <class 'float'>)\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Here are the calculations step by step:\n",
      "\n",
      "1. 11 + 53 = 64\n",
      "2. 64 × 2 = 128\n",
      "3. 128 ÷ 16 = 8\n",
      "\n",
      "The final result is 8.\n"
     ]
    }
   ],
   "source": [
    "# get messages and tool outputs\n",
    "for m in react_output[\"messages\"]:\n",
    "    m.pretty_print()\n",
    "    if isinstance(m, ToolMessage):\n",
    "        print()\n",
    "        print(f\" --> Tool artifact: {m.artifact} (type: {type(m.artifact)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca6935a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Add 11 and 53. Multiply the output by 2. Then divide it by 16', additional_kwargs={}, response_metadata={}, id='cb48bba3-2b4a-48c9-ae48-d092bf5edf0b'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_rSHI6ZW1ETy4YXFI7f3QRyjY', 'function': {'arguments': '{\"a\":11,\"b\":53}', 'name': 'add'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 145, 'total_tokens': 162, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_51e1070cf2', 'id': 'chatcmpl-BlkgfUlmJDSFL3BpoTJsiDkALMmNP', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--60894b5d-67d2-4d00-a8e1-f63deb2229c1-0', tool_calls=[{'name': 'add', 'args': {'a': 11, 'b': 53}, 'id': 'call_rSHI6ZW1ETy4YXFI7f3QRyjY', 'type': 'tool_call'}], usage_metadata={'input_tokens': 145, 'output_tokens': 17, 'total_tokens': 162, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content='Adding 11 and 53 gives 64', name='add', id='07ab4455-8789-4942-b063-a8bcbacf7941', tool_call_id='call_rSHI6ZW1ETy4YXFI7f3QRyjY', artifact=64),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_MZtbJwdrNGcMMa1aku3Hc1Mn', 'function': {'arguments': '{\"a\":64,\"b\":2}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 178, 'total_tokens': 195, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_51e1070cf2', 'id': 'chatcmpl-BlkggckXbX2sqKhcFpeWlo5CgDfAt', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--d73ae3dd-27a4-4e1f-8d8c-e2478b8a53bd-0', tool_calls=[{'name': 'multiply', 'args': {'a': 64, 'b': 2}, 'id': 'call_MZtbJwdrNGcMMa1aku3Hc1Mn', 'type': 'tool_call'}], usage_metadata={'input_tokens': 178, 'output_tokens': 17, 'total_tokens': 195, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content='Multiplying 64 and 2 gives 128', name='multiply', id='0a0602cb-88fe-4969-a938-3aa39ead9d7f', tool_call_id='call_MZtbJwdrNGcMMa1aku3Hc1Mn', artifact=128),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_CMMhyRUb11Vzy6ep5YdFesle', 'function': {'arguments': '{\"a\":128,\"b\":16}', 'name': 'divide'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 212, 'total_tokens': 229, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_51e1070cf2', 'id': 'chatcmpl-BlkghlQhplvyWuGTlhsuWmEEWBT3u', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--90532977-ddbc-4b10-9da1-bea7c622c653-0', tool_calls=[{'name': 'divide', 'args': {'a': 128, 'b': 16}, 'id': 'call_CMMhyRUb11Vzy6ep5YdFesle', 'type': 'tool_call'}], usage_metadata={'input_tokens': 212, 'output_tokens': 17, 'total_tokens': 229, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content='Dividing 128 by 16 gives 8.0', name='divide', id='1c6e4cff-c7b5-4eee-8017-1a68ddfe6491', tool_call_id='call_CMMhyRUb11Vzy6ep5YdFesle', artifact=8.0),\n",
       "  AIMessage(content='Here are the calculations step by step:\\n\\n1. 11 + 53 = 64\\n2. 64 × 2 = 128\\n3. 128 ÷ 16 = 8\\n\\nThe final result is 8.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 50, 'prompt_tokens': 248, 'total_tokens': 298, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_51e1070cf2', 'id': 'chatcmpl-BlkgiWLPybGq933Hd1FM54AUw6nLv', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--27d6b022-731b-43cd-84a6-9528d015e0df-0', usage_metadata={'input_tokens': 248, 'output_tokens': 50, 'total_tokens': 298, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "react_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3ee2b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the calculations step by step:\n",
      "\n",
      "1. 11 + 53 = 64\n",
      "2. 64 × 2 = 128\n",
      "3. 128 ÷ 16 = 8\n",
      "\n",
      "The final result is 8.\n"
     ]
    }
   ],
   "source": [
    "final_message = react_output[\"messages\"][-1]\n",
    "print(final_message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff380f6",
   "metadata": {},
   "source": [
    "## Explore Further\n",
    "\n",
    "### Persistance\n",
    "\n",
    "Langchain agents can have [two types of memory](https://langchain-ai.github.io/langgraph/how-tos/persistence/):\n",
    "\n",
    "1. **Short-term (within-thread) memory (a.k.a. checkpointers)**: Chatbot can persist conversational history and / or allow interruptions in a chat session \n",
    "2. **Long-term (cross-thread) memory (a.k.a. stores)**: Chatbot can remember information about a specific user *across all chat sessions*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
