{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b78efe2d",
   "metadata": {},
   "source": [
    "# ReAct Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b10f58",
   "metadata": {},
   "source": [
    "In this notebook we will build a [ReAct](https://react-lm.github.io/) agent, a general tool-calling agent architecture that:\n",
    "- lets the model call specific tools\n",
    "- passes the tool output back to the model\n",
    "- lets the model reason about the tool output to decide what to do next (e.g., call another tool or just respond directly)\n",
    "\n",
    "This [general purpose architecture](https://blog.langchain.dev/planning-for-agents/) can be applied to many types of tools. \n",
    "\n",
    "![ReAct architecture](https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F06f2cf46-df40-48f9-a798-931222b0f70a_590x592.png)\n",
    "\n",
    "The complete implementation of the ReAct agent can be found on `src/hackathon/agents/react/agent.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6945fa",
   "metadata": {},
   "source": [
    "## Define LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1367c28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from hackathon.config import OLLAMA_MODEL\n",
    "\n",
    "llm = ChatOllama(model=OLLAMA_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5a5f34",
   "metadata": {},
   "source": [
    "## Define State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34964478",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from typing import Annotated, Any\n",
    "from operator import add\n",
    "from langchain_core.messages import AnyMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "# define the state\n",
    "class ReActState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]  # same as in langgraph.graph.MessagesState\n",
    "    tool_outputs: Annotated[list[Any], add]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684f78b2",
   "metadata": {},
   "source": [
    "## Define Tools\n",
    "\n",
    "Here we define the tools using the `@tool` decorator. We set `response_format=\"content_and_artifact\"` to save the artifacts of a tool's execution that we want to make accessible to downstream components of the graph or backend APIs. \"For example if a tool returns a custom object, a dataframe or an image, we may want to pass some metadata about this output to the model without passing the actual output to the model. At the same time, we may want to be able to access this full output elsewhere, for example in downstream tools.\" ([see docs](https://python.langchain.com/docs/how_to/tool_artifacts/))\n",
    "\n",
    "This way, we distinguish between the parts of the tool output meant for the model (this is the ToolMessage.content) and those parts which are meant for use outside the model (ToolMessage.artifact)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca9f8643",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool(response_format=\"content_and_artifact\", parse_docstring=True)\n",
    "def add(a: int, b: int) -> tuple[str, int]:\n",
    "    \"\"\"Adds a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    result = a + b\n",
    "    message = f\"Adding {a} and {b} gives {result}\"\n",
    "    return message, result\n",
    "\n",
    "@tool(response_format=\"content_and_artifact\", parse_docstring=True)\n",
    "def multiply(a: int, b: int) -> tuple[str, int]:\n",
    "    \"\"\"Multiply a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    result = a * b\n",
    "    message = f\"Multiplying {a} and {b} gives {result}\"\n",
    "    return message, result\n",
    "\n",
    "@tool(response_format=\"content_and_artifact\", parse_docstring=True)\n",
    "def divide(a: int, b: int) -> tuple[str, float]:\n",
    "    \"\"\"Divide a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    if b == 0:\n",
    "        raise ValueError(\"Cannot divide by zero\")\n",
    "    result = a / b\n",
    "    message = f\"Dividing {a} by {b} gives {result}\"\n",
    "    return message, result\n",
    "\n",
    "tools = [add, multiply, divide]\n",
    "\n",
    "# Bind tools to the LLM\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a18817",
   "metadata": {},
   "source": [
    "## Define ReAct agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81deb700",
   "metadata": {},
   "source": [
    "### Nodes\n",
    "\n",
    "[`ToolNode`](https://langchain-ai.github.io/langgraph/reference/agents/#langgraph.prebuilt.tool_node.ToolNode) is a useful shortcut if you want to create a node to execute tools.\n",
    "\n",
    "The `ToolNode` is roughly analogous to:\n",
    "\n",
    "```python\n",
    "tools_by_name = {tool.name: tool for tool in tools}\n",
    "def tool_node(state: dict):\n",
    "    result = []\n",
    "    for tool_call in state[\"messages\"][-1].tool_calls:\n",
    "        tool = tools_by_name[tool_call[\"name\"]]\n",
    "        observation = tool.invoke(tool_call[\"args\"])\n",
    "        result.append(ToolMessage(content=observation, tool_call_id=tool_call[\"id\"]))\n",
    "    return {\"messages\": result}\n",
    "```\n",
    "\n",
    "the [`tools_condition`](https://langchain-ai.github.io/langgraph/reference/agents/#langgraph.prebuilt.tool_node.tools_condition) is a simple router used to build the ReAct's conditional edge:\n",
    "- If the latest message from assistant is a tool call -> tools_condition routes to `\"tools\"` (we need to make sure to name the tool node as `\"tools\"`)\n",
    "- If the latest message from assistant is a not a tool call -> tools_condition routes to `END`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56018a47",
   "metadata": {},
   "source": [
    "### Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae9cfea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, END, StateGraph\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage, ToolMessage\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# System message\n",
    "sys_msg = SystemMessage(content=\"You are a helpful assistant tasked with performing arithmetic on a set of inputs.\")\n",
    "\n",
    "# Nodes\n",
    "def llm_node(state: ReActState):\n",
    "   return {\"messages\": [llm_with_tools.invoke([sys_msg] + state[\"messages\"])]}\n",
    "\n",
    "tool_node = ToolNode(tools)\n",
    "\n",
    "# Graph\n",
    "react_builder = StateGraph(ReActState)\n",
    "\n",
    "# Define nodes\n",
    "react_builder.add_node(\"llm\", llm_node)\n",
    "react_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "# Define edges\n",
    "react_builder.add_edge(START, \"llm\")\n",
    "react_builder.add_conditional_edges(\"llm\", tools_condition)  # routes to \"tools\" or \"__end__\"\n",
    "react_builder.add_edge(\"tools\", \"llm\")\n",
    "\n",
    "# Compile the graph\n",
    "react_graph = react_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08efc4f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANgAAAD5CAIAAADKsmwpAAAAAXNSR0IArs4c6QAAHh1JREFUeJzt3WlYE+eiB/B3su+BJOyLgCgKSEVQLO7iWqWKdcEeb7U+rW1tT8tR66m11tae9urVHk+lLherVr1WreJel0M3pCgVUFBAXECRnQAh+565H9KHcmJYzWTekPf3+AFIMvNX/r55ZzILhuM4QBCyUcgOgCAAFRGBBSoiAgVURAQKqIgIFFARESjQyA4AHYPO3Fxr0CjNGqXJbMKNBhfYvcVkU2gMjMOncfgUn2A22XH6AkP7Ea00KtODQlVlibq1Qe/hzeDwqRw+TSCiGfUu8O9DZ1FkDQaN0kRjYFV3NWHRvLAY7sAYHtm5egEVEeA4fu18S8NjrVcQKyyaGziIQ3aiZ2LQWSpLVNX3tLUPtYnJ4sEj+GQn6hF3L+Ld3xU/HWtKTBaPmOxJdhYHU8qM1863aJSmaf/lyxXAPgdz6yJePSWl0sGYZC+ygxCotVF/ZmfdlJd9godAPdK7bxF/OdEk8mE8N96D7CDOcHZP7egXxD7BLLKDdMpNi3g+oy4ogjN8glu00Ors7tohIwUR8ZBOGd1xP+K1883+A9lu1UIAwJy3Am7+LGuu05MdxD63K+KDW0oAQFxSf9s06YnFa4OvnpLiFhjfA92uiNmZ0thJ7thCq7BhvN/ONpOdwg73KuKtX2VD4gVsHpXsIKQZPsHjwS2VWmEiO4gt9yri41L188kislOQbPw8SVF2G9kpbLlRER+XqWl0CpXqRn9lu4KHcEty5WSnsOVGv5VHd9Shw7hOXukHH3xw9uzZPrxw6tSptbW1BCQCDBbFK5BZ+1BLxML7zI2K2NpkGOj0IpaVlfXhVfX19TKZjIA4fxgcy6t5qCFu+X3gLkU06CzNtXo2j6iPXHNzc994442xY8fOnTt348aNzc3NAID4+Pi6urrPPvts4sSJAACVSrVnz56lS5dan7Z9+3adTmd9eVJS0tGjR19//fX4+Pjs7Ozk5GQAwJw5c1avXk1EWq6QLq2BbIci7h5aG/WHP39M0MLv3r0bFxe3d+/e+vr63Nzc1NTUt99+G8dxnU4XFxd35swZ69P27t2bkJCQlZWVn5//888/z5w586uvvrI+NH369AULFmzdujUvL89oNObk5MTFxdXU1BAUuLFKe+zLJwQtvG9gPyjDUdRyE1dI1F+2qKiIxWItX76cQqH4+vpGRkY+fPjw6actWbIkKSkpNDTU+m1xcfG1a9feffddAACGYUKhcM2aNQQltMEV0tRyuPbguEsRLRbAYBM1Dxk+fLhOp0tLS0tISBg/fnxQUFB8fPzTT6PT6devX9+4ceP9+/dNJhMAQCT6c19SZGQkQfGeRqFhDBZcszK40hCHK6DKpUaCFj5kyJAdO3Z4eXmlp6enpKSsXLmyuLj46aelp6dnZGSkpKScOXOmoKDg1Vdf7fgog8EgKN7T1G0mKg1z2up6wl2KyBHQNER+nJCYmLhhw4bz589/8skncrk8LS3NOua1w3E8MzNz0aJFKSkpvr6+AAClUklcnq6pFSbYDpV1lyKyuVRJANNktBCx8MLCwmvXrgEAvLy8Zs+evXr1aqVSWV9f3/E5RqNRq9V6e3tbvzUYDFevXiUiTE/oNRbvICZZa7fLXYoIAGDzqJV31EQsubi4eO3atadOnZLJZCUlJceOHfPy8vLz82Mymd7e3nl5eQUFBRQKJSQk5Ny5czU1NW1tbZs2bRo+fLhCoVCr7UQKCQkBAGRlZZWUlBAR+P5Npc8AuA6SdaMihkZzH5UQUsQlS5akpKRs27Zt6tSpK1as4HK5GRkZNBoNALB8+fL8/PzVq1drtdovvviCxWLNnz9/7ty5o0aNeuedd1gs1pQpU+rq6mwWGBgYmJycvGfPnvT0dCICPy7ThEY5e99+19zoCG2D3vLDvvqUlQFkByHZk3uayjuqifO9yQ7yH9xoRGQwKd6BzJs/E/jRmUu4dq456nkh2SlswbXpRLTE2eKdayo6O3PUYrFMnjzZ7kMGg4FOp2OYnV0eYWFh+/fvd3TSPxQVFaWlpfU20uDBgzMyMuy+6v5NpacPwysAri0V93prtiq+2max4LET7Xexs10qer2eybT/y8MwjMcj8JoKfYhEoVC4XPtTwB/21Y1L8RKI6A7N6ABuV0QAwMX99RHxfNe6IodDwPwXd6M5YrsXlvtdv9DSVK0jO4hTZWdKxX4MOFvopiPiH59zfFUzepbY1a9000PZmVLvYObQkQKyg3TKHUdE68RuflpQ/r9lpXnQHTTvWDiOn91dKxDRYG6h+46I7a7/0PyoVJM4WxwSCdcOXocoyGotzVNMWugdHAH7wO/uRQQAtNTpr11oYbIpAYPYoVFcDt/ld2lJa/RVd9WFP8lixnkkzBRRKHAdaGMXKuIfaiu09/KVj0rVnj50kQ+DK6RxBTSukGo2k52sBzAMV7aa1AozbsHv31SxuJTw53gx4zxgO+iwC6iIthoea6W1BrXcpFaYKBRMo3RkE7VabWVlZVRUlAOXCQDgedIADrgCKt+T5j+QzfeEbjdht1ARnaqiomLdunXff/892UGg4zJDN9K/oSIiUEBFRKCAiohAARURgQIqIgIFVEQECqiICBRQEREooCIiUEBFRKCAiohAARURgQIqIgIFVEQECqiICBRQEREooCIiUEBFRKCAiohAARURgQIqIgIFVEQECqiIToVhWPsdLpCOUBGdCsfxpqYmslPACBURgQIqIgIFVEQECqiICBRQEREooCIiUEBFRKCAiohAARURgQIqIgIFVEQECqiICBRQEREooCIiUEBFRKCAbvjjDKmpqRqNBgBgMBhaWlr8/Pyst6C/cuUK2dFggUZEZ5gzZ05DQ0NdXV1zczOO43V1dXV1dXw+n+xcEEFFdIbU1NTg4OCOP8EwbOzYseQlgg4qojNgGDZv3jwqldr+kwEDBixatIjUUHBBRXSShQsXBgUFWb/GMGzChAnWmSJihYroJDQaLTU1lclkAgACAwPnz59PdiK4oCI6z7x58wIDAwEAiYmJaDi0QSM7gIsxGS2tjQZVmwkArA8vT056LcuSNXHUosoSdR9eTqEATx+GUOx69wXvFtqP2As3rrTev6mkUikeXgyjweL8ADxPWnW5WujFGDnVMyCc7fwAxEFF7Kmc080mM4ifKiE7CNDrzFmH6iYt8PINYZGdxWHQHLFHrl1oseBQtBAAwGRRZ68IyjrSKGs0kJ3FYVARu6eWm+ortSOSoGhhu9HJ3vlZMrJTOAwqYvdaGw0A68umCaGEEvqTcg3ZKRwGFbF7qjaTpw+T7BS22FwaV0DT60jYZiICKmL3cAsw6mH8fStaDBT4huq+QUVEoICKiEABFRGBAioiAgVURAQKqIgIFFARESigIiJQQEVEoICKiEABFRGBAioiIebOm3Lo8DcAgMrKh5OS4u/cKSI7EexQEREooCIiUEBn8TnPp5s+wDDs+dHjtn75GZVKHRIR9cnGLWfOnjh4KEMgEE6fNvvNN97D+sthXb2Fiug8NBqt+PZNPl9w4viltjbZaysWv/e31yeMT7pwLvve/bJVq9+MHR4/erSbXhAHvTU7lcFgeOftNUKhx4ABoWGh4VQq9dVlb3I4nNjh8R4enhWVD8gOSBo0IjpVQEAQnf7H6fFsDkcs+vOELC6Hq1IpyYtGMjQiOhWFQuniW3eG/iEQKKAiIlBARUSggIqIQAFdhKl7ZXmK6ge6xBe9yQ5i67svKpZvCqMz+8M+cDQiIlBARUSggIqIQAEVEYECKiICBVREBAqoiAgUUBERKKAiIlBARUSggIrYPaPRCNDnoARDRexGeXn5tm3b+nS/M6QXUBG7UVVVtW7dOrJT9H+oiPYVFha+8sorAIDp06fTGBiTDeM/lDiAefLUieLiYpVKRXaWZ4VOnrLvypUr+/fvt34t9mXk/1sWN5XsTP9J1qRvbmjbe3CLQCDg8XgikSgsLGzkyJHh4eGDBw8mO12voeMR/8PNmzfv3LmzdOlSm5+f+rp23Eu+LA6VpFx23CuQy1vb0o+8V1NTAwDAcRzHcQqF4uHhQafTL126RHbA3oHxHYcsbW1tu3fvTk1NffqhsXMlPx6pIyOUfU/KVRVFiqQFA6Kjoy0WCwAAwzDrOYFtbW1MJnT3yeoWGhGBddOYRqP5+Pjw+fzOniNrNBzbVj1qpkQgYfA9aDhOwoY0hoGWep1SZnxcolq0KhCjYHfv3l21apVUKm1/jqenZ1ZWlvOzPSNURFBUVLR169Zvv/22/dT3zpgMlhv/bq2v1Bn0uEFj7sO6LDhuNBqZDEbfoor8mRgAwUPYMeM82n+YlpaWk5NjvWgOjuOZmZkhISF9Wz6ZcDdWX1+P4/jt27edtsaHDx8uWLDAscvMy8ubOHFiXFxcbGysRqOZN2/ehQsXHLsKJ3DfOWJWVtbf//53AMCwYcOctlJvb++VK1c6dpkJCQmDBg0ym803b95ks9mZmZm///771q1bHbsWwpH9P4EEarUax/ETJ06QHcSRpk6d2vHbo0ePLlu2jLw4veZ2RTx9+vS2bdvIWntTU9POnTuds67i4uJRo0bdu3fPOat7Rm701myxWPR6/Z07d1avXk1WBoVC8euvvzpnXTExMbm5uRs3bjx79qxz1vgs3GWr+cqVKzweb/To0VQqmTullUplYWHhxIkTnbnSTZs20Wi0Dz/80Jkr7S23GBFv376dnZ09ZswYclsIAODz+U5uIQDg448/joiIWLJkCdSDDtlzA2Ll5ua276aBgTPniDbKysri4uJKSkpIWXu3+vOIeO7cuaNHjwIAfH19yc7yB2fOEW0MHTq0oKBgy5YtJ06cICVA1/pnESsrKwEA/v7+6enpZGf5D0TsR+yVQ4cOVVRUfPrppyRmsKsfbqzs2rXLZDK9++67ZAeB17lz544cOXL48GFGXz9sdLh+NSIqFAoAgEgkgraFUql0165dZKcAL7744ueffz5hwoSiIljuzdZ/irh3794bN24AAOwexwUJEueINsLDw69fv56env7dd9+RnQX0kyJaLJaysjKz2TxlyhSys3SD9DmijX379tXX169fv57sIK4/Rzx27NiUKVO4XC6bzSY7i6u6fPlyRkbGoUOHeDweWRlce0Q8efJkdXW1RCJxlRZCMke0MWPGjO3bt8+aNSs/P5+sDK5axOzsbADA6NGj33//fbKz9AI8c0QbAwYMyM7O3rdv38GDB0kJ4JJF3Lx588OHDwEAgYGBZGfpHdjmiDb27Nkjl8vXrl1LwrrJ/mindyorK3Ecz8/PJztIf/bjjz/OmjVLJpM5c6WuNCJ+9NFH1oEwPj6e7Cx9BOcc0UZSUtLevXtfeuml3Nxcp63UNYqoVqtramrGjBkzdSpkp7n3ErRzRBt+fn4//fTT8ePHv/nmG+es0QWKuHnz5ubm5oCAgJkzZ5Kd5VlBPke0sWPHDqPR+Le//c0J64J9P2JmZqbFYlmwYAHZQdzX1atXP//888OHD3t7E3nvLWdOSHtl3759OI5rtVqygzgSiccjPgupVDpjxoyioiLiVgHpW/OpU6eam5sBACwWi+wsjsRisW7dukV2il6TSCSXLl3auXNnbW0tQauA9K25sbGRxWIJhUKygzie0Wg0mUwYhrnc/7H4+Pj8/HzrJSUcDtIR0cfHp1+2EABAp9PZbPbx48fr6+vJztIL5eXlERERBLUQ3iIeOHDg8uXLZKcg0NKlS9PS0shO0Qt3794dOnQoccuHtIhSqVQul5OdgljHjx8HAFRXV5MdpEfKysoiIyOJWz6kRVy+fPmMGTPITuEM2dnZhYWFZKfonpuOiBKJpL/OEW0sWbLEJa7uWl5e7o5F7PdzxI4++ugjAEBeXh7ZQTpVVlZGaAvhLaI7zBFt1NTUXLlyhewU9hH9vgxvEd1njthu/vz51rMQIUT0lgq8RXSfOWJH1o/UrVengIr7johuNUe0IRaLT548SXaKP1kslgcPHkRERBC6FkiL6IZzxHbTpk2D6mrsTnhfhreIbjhH7Mh6CPrHH39MdhDgnPdleIvonnNEGykpKUeOHCE7hXsX0Z3niO1iY2MnTZpEdgr3fmt25zliR/7+/tahkawAJpPp0aNHgwYNInpFkBbRzeeINvbs2XP48OGOP5k2bZpzVu2c4RDeIqI5Ykc+Pj6LFi1SqVRarRYA8MILL7S0tDjn4uzOmSDCe7/mAwcO+Pn5oUGxHYPBYDAYY8eO9fDwaGpqwjCstLS0tbVVJBIRut6ysrKRI0cSugorSEdENEe0SywWNzQ0WL9ubW3Nyckheo1OGxEhLSKaIz7tpZde6njuklqtJvp2uAaDobq6euDAgYSuxQrSIqI5oo2UlJRHjx5Z7xFuRaFQqqqqrJetJ4jTtlTgLSLaj2jj9OnTKSkpISEhHh4e1s9/rec6Evru7LT3ZXg3VqRSKYfDITsFXDZs2GC9i1ZOTk5OTk5LS4tcpsn+6ca8F/9C0BrvlT6JjY1Vykx9XgKOA4GoRx2D67zmyZMny+Xy9kgYhuE47uvre/HiRbKjwaUgq/X2bzILZjLpcTZh50ebTCYqjfYsJ5B6+jFrH2jCn+MmvCAWiOhdPBOuETExMfHixYsUyp8TBgqFkpycTGoo6Fw+2MAT0WcuD+Z5dPWrhYTJaGlrMpz4qmbe2wGe3p3e1gWuOeLixYutH2q1CwwMXLx4MXmJoHPp2wZPX+Zz48Uu0UIAAI1OkQSwFq4KPb2zVtFq7OxpcBUxKioqOjq6/VsMw2bMmGGdniMAgMdlagabGjnak+wgfTFpkV/exdbOHoWriACAV155RSKRWL8ODAxcuHAh2Ykg0lStpzOh+5X1kKcP82GRsrNHoftbRUZGxsTEWL+eOXOmp6dL/u8niF5jlvgxyU7RR1QaFhzBbZMa7D4KXREBAMuWLROLxb6+vmg4tKFWmE2dzrJcQGujobPLOD3rVnNdhUbebFIrTRqF2WIGJpOlBy/qlnhsxFtcLrfgkh6AxmdfHJNNwQDGEVA5AqrYn+nl76qDSj/WxyJW3VXfv6mqLFF7+rJxHKPSqRQ6lUKlOmqvZHTMRACAUu2QhQGVBrOYzeZak9mgM+rkRp15YAx3SDzfZ4CLXaGwH+t1Eesfaa+ebqFzGBiNOfB5TxqdSkwwAhm0ppZmdfYZGZsDxs0Ve3jBcs9id9a7Iv54VFpXqROHirieLjyWMNg0UZAQAKBoUmem1w0dxU+cLSY7lLvr6caKyWj5dlOVzswMHuHv0i3sSODNHfh8UFMD5fROoi4NjfRQj4poNuEZ6yr9In14Yi7xkZzNI0BAFwqObXONC2b2V90X0WLBd6+tiEwKZXJd4zOlPuCJOYIA0cF/VJEdxH11X8Qj//1kUGKAU8KQiePBEgV5/LDPlS6w3p90U8RfM5s9gjyYXLfYruR784yAWZTdRnYQd9RVEVvq9I9K1HwvnhPzkMzDX/jbmWaojtF0E10V8eqZFkkosWcrQsh3sGfOmRayU7idTovY8FhrMlP4XpAer19058c1GxJUapnDlywJ8ait1Ou1Zocv2UXNnTfl0GHCb5bbaREfFqsxar/dTO4GRnlcqiE7hGN8uumDi5fOkp2ie50WseK2mu8N6XBINI6I+6BIRXYKx7h3r4zsCD1i/yM+WZOBzacTt7H8+Mntf//yTXVNGY/rOTRi7LRJr7FYXABAbt6JrOz9by3ffejYusamSj+f8PGJi0eOmG191YXL6QXFF5kMTmzMdG9JMEHZAAACb059KaTXVe+VSUnxAICt2z7bvWf7+bO/AgByc7MPHsqoevJIKPQID494769/9/HxtT65i4fa5f2ee/z4ofJ7pSKRJDr6uRWv/VUsljgkqv0RUdVm0mkdckCXHc0t1f/77V+NRv07K75Z+vKW+sYHu/e/ZTabAABUGl2rVZ75YdvCuR9u3ZQXEz35+zP/kLU1AACu3ci8duPkvFnvv/fGAbGnf9Yv+wiKZz1FQSUzqhV9P40SEpcv5gIA3l+zwdrCgsLfP/7k/WnTZn1/7OLGDZsbG+v/tWOz9ZldPNTu/oPydR++Fxs78tv9J9/969qKivtb/ucTR0W1X0SNwkwl7LCam8WXaVT6ssVbfLxCfL3DFsxZX1t/r+RutvVRs9k4ddJrA4KGYRgWP3wWjuO19fcBAL9d/z4mKikmejKHIxg5YnZ4WDxB8awYLKpa7vJFtLH/wO7x4ybPf+llodAjKipm5Vur8vJ+K79X1vVD7UruFLFYrCV/We7j45swKvHLrbsXL17mqGydFFFpojKIOtP08ZPbQYGRXO4fp0SJPP3EosBHVUXtTwgOiLJ+wWELAABanRLH8ebWah/v0PbnBPoPISieFZ1N1bj+iGijsvLBkCFR7d9GDI4EAJSXl3b9ULvoYcN1Ot269WknTh6pqa0WCj1ihztsOOi0bRggaqeuVqeqri1bsyGh4w8Vyj933T19NLlOr7ZYzEzmnxtPDAaboHhWFjMAhN2bmBQqlUqv1zOZfx45Zb2Whkaj7uKhjksYPGjI5v/ecfXqTxl703ft3h43YtSypW9ERz/nkHj2i8gR0MxGnUNW8DQ+Xxw6YPj0ySs6/pDL7eqSSywml0KhGjtE0huI3b1iNpi5AriuPvCMWCwWAECn07b/RK1RAwDEIkkXD9ksJGFUYsKoxFeXvVlY+HvmqaMfrk87fepHKtUBszj7b80cPtVsJGqPrr/PoDZ5Q1hIbHhYnPUPj+fpLenqziIYhnl6+D1+cqf9J3fv5RIUz8qgM3MErnfweRdoNFrE4KGlpbfbf2L9OmzgoC4e6riEoqLC329cAwBIJF7Tp89+e+VqpUrZ3Cx1SDz7RRSIaHQGUW9M4xMXWyyWc5e2Gwy6JmnVhStff/n1y/WND7t+1XPRU+6U/VJ050cAwM85h6pqSgiKZz3yjedB6wcjIpPJ9PLyLijIu1VUYDKZUuYu+i3318zMowql4lZRwa7d/xwRO3JQeAQAoIuH2pWUFn/y6drzF061tcnK7pacOn1MIvGSSLwcEtX+v7VQwjDpzDqlgcV3/K5EDkew5p3vfsk5/K89S5ukj4MDoxbMXd/txseUCa+q1bIzF7/8v+/Xhw4Y/uLMtO9OfEzQ0QmKRrWndz/5VOkvLy8/8O2eG/nXjn53Ydq0WdLmpuMnDn+960sfH9/4uNGvv/aO9WldPNRu4YIlbW2yr3du++f2LxgMxuRJ07f/M8Mh78tdXQ3s+g8tNY9xrzB3PL+9rrRpZBJvUCyf7CC2Lh9s8B/ICx3mqsdDnU6vmvOmv1Bi5z95px/xhT/HxU39bf9FD2GYOTSqH54UAbNOp0FegSw2B5c3qoU+9n8lbfKmbV/bv04Xm8nT6u1/VuvrFfbOir19TWvHR58ndfaQ2WyiUu38BYMDo1Ys3dHZq6SVstBINo0B4zUw+rGu5uPj50lO/qu2syLyeaJVKw/bfchg0DEY9s/0o1AcvAXQWQYAgMGoZ9DtXNSBRut04msxW6SP5Avedsbly5GOuqqFUEwfmsBrkSr5XnZmS1QqTeTpb+91TuXYDIp6+cQFjvkUH+mVbt6AEmdLNM0qTRtRO7ehIq9X8LiWyAR0NwMSdD8TWrQq8MmtBqOun2+4tDWotK2qKS97kx3ETfVoSv7GlrAHudX9eFyUN6iATp26JojsIO6rR0XEMGzltnBFbauisdMrfrouWbWMgWnnvkX+fNed9WInReqaILHYXJlXo2hy0OXiyCarVZT/WhUaQZu5zPZQZMTJerczZUyyODKBf/V0S3OFBqfSBV5cV7wOiVahV0o1Fr1e4k9/4ZMBTHa/OrjBRfV6r56nN2POG34Nj3UPilQVtxuZHJrFglEZVCqdSqFRAWFHMT4LDMNMRrPFYDIZzAatkcmmDBrOGzzCC10ZER593L3sG8LyDWGNmytpbTDIm41qhUktN5lNFrMJxiIyWBiFSuEKOBwBVRLA4AldbxTv9571cw6RL0Pki8YV5FmhT1RdCVdIc+mLHoh8mZ1N3lARXQmbS2mu1ZOdoo+MBkvNfbVQYv/9ExXRlfgMYBn1rnpRntYGfReHeKIiupKgwRwMA7d+dsmLlf38Xd2YFzu9aD5c92tGeuLqKanRiA+MEYj9XeCq+mqFSS7V/3Ks4b/WB3M731+BiuiSSq7LS68pdBqznrArwziEVwCzrckQOow7JlnS9e0sURFdGI4Dgw7qIuIWnMXt0QdXqIgIFNDGCgIFVEQECqiICBRQEREooCIiUEBFRKDw/9bByS2bQy7OAAAAAElFTkSuQmCC",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show Graph\n",
    "display(Image(react_graph.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b98c300",
   "metadata": {},
   "source": [
    "### Run ReAct Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f2a9b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input\n",
    "messages = [\n",
    "    HumanMessage(content=\"Multiply 375 by 12897\"),\n",
    "]\n",
    "\n",
    "# Run the graph\n",
    "react_output = react_graph.invoke(input={\"messages\": messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb0f332d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Multiply 375 by 12897\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "<think>\n",
      "Okay, the user wants to multiply 375 by 12897. Let me check the available functions. There's a multiply function that takes two integers, a and b. So I need to call that function with a=375 and b=12897. I should make sure both numbers are integers, which they are. Alright, the tool call should be straightforward.\n",
      "</think>\n",
      "Tool Calls:\n",
      "  multiply (b24e2533-bd61-48fd-9eb9-a22db89eb665)\n",
      " Call ID: b24e2533-bd61-48fd-9eb9-a22db89eb665\n",
      "  Args:\n",
      "    a: 375\n",
      "    b: 12897\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "Multiplying 375 and 12897 gives 4836375\n",
      "\n",
      " --> Tool artifact: 4836375\n",
      " --> Tool artifact data type: <class 'int'>\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "<think>\n",
      "Okay, the user asked to multiply 375 by 12897. I used the multiply function with those numbers. The result came back as 4836375. Now I need to present this answer clearly. Let me check if the multiplication makes sense. 375 times 10,000 is 3,750,000. 375 times 2,000 is 750,000. Adding those gives 4,500,000. Then 375 times 897... Hmm, maybe breaking it down further would help, but the function already gave the correct result. So I'll just state the answer clearly.\n",
      "</think>\n",
      "\n",
      "The product of 375 and 12897 is **4,836,375**.\n"
     ]
    }
   ],
   "source": [
    "# get messages and tool outputs\n",
    "for m in react_output[\"messages\"]:\n",
    "    m.pretty_print()\n",
    "    if isinstance(m, ToolMessage):\n",
    "        print()\n",
    "        print(f\" --> Tool artifact: {m.artifact}\")\n",
    "        print(f\" --> Tool artifact data type: {type(m.artifact)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca6935a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Multiply 375 by 12897', additional_kwargs={}, response_metadata={}, id='8fbf3ad2-80ca-4d08-b836-0006d2af01f8'),\n",
       "  AIMessage(content=\"<think>\\nOkay, the user wants to multiply 375 by 12897. Let me check the available functions. There's a multiply function that takes two integers, a and b. So I need to call that function with a=375 and b=12897. I should make sure both numbers are integers, which they are. Alright, the tool call should be straightforward.\\n</think>\\n\\n\", additional_kwargs={}, response_metadata={'model': 'qwen3:14b', 'created_at': '2025-06-23T03:01:14.955332Z', 'done': True, 'done_reason': 'stop', 'total_duration': 14101777791, 'load_duration': 35025458, 'prompt_eval_count': 295, 'prompt_eval_duration': 5326089916, 'eval_count': 119, 'eval_duration': 8727744167, 'model_name': 'qwen3:14b'}, id='run--d2e0fd00-5a10-42f2-922d-2faf2820cba8-0', tool_calls=[{'name': 'multiply', 'args': {'a': 375, 'b': 12897}, 'id': 'b24e2533-bd61-48fd-9eb9-a22db89eb665', 'type': 'tool_call'}], usage_metadata={'input_tokens': 295, 'output_tokens': 119, 'total_tokens': 414}),\n",
       "  ToolMessage(content='Multiplying 375 and 12897 gives 4836375', name='multiply', id='2a93451c-9820-437a-83e2-5f8b5f924855', tool_call_id='b24e2533-bd61-48fd-9eb9-a22db89eb665', artifact=4836375),\n",
       "  AIMessage(content=\"<think>\\nOkay, the user asked to multiply 375 by 12897. I used the multiply function with those numbers. The result came back as 4836375. Now I need to present this answer clearly. Let me check if the multiplication makes sense. 375 times 10,000 is 3,750,000. 375 times 2,000 is 750,000. Adding those gives 4,500,000. Then 375 times 897... Hmm, maybe breaking it down further would help, but the function already gave the correct result. So I'll just state the answer clearly.\\n</think>\\n\\nThe product of 375 and 12897 is **4,836,375**.\", additional_kwargs={}, response_metadata={'model': 'qwen3:14b', 'created_at': '2025-06-23T03:01:36.488596Z', 'done': True, 'done_reason': 'stop', 'total_duration': 21496175000, 'load_duration': 42386917, 'prompt_eval_count': 419, 'prompt_eval_duration': 652214917, 'eval_count': 190, 'eval_duration': 20762526417, 'model_name': 'qwen3:14b'}, id='run--1fcb108c-892b-489c-9ba0-3daf51dddc5c-0', usage_metadata={'input_tokens': 419, 'output_tokens': 190, 'total_tokens': 609})],\n",
       " 'tool_outputs': []}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "react_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe8c756",
   "metadata": {},
   "source": [
    "### Check agent's final answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36d0a787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The product of 375 and 12897 is **4,836,375**.\n"
     ]
    }
   ],
   "source": [
    "from hackathon.utils import remove_thinking_tags\n",
    "\n",
    "final_answer = react_output[\"messages\"][-1].content\n",
    "print(remove_thinking_tags(final_answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2f29c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4,836,375\n"
     ]
    }
   ],
   "source": [
    "# check if the math is correct\n",
    "math_result = 375 * 12897\n",
    "print(f\"{math_result:,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff380f6",
   "metadata": {},
   "source": [
    "## Explore Further\n",
    "\n",
    "### Persistance\n",
    "\n",
    "Langchain agents can have [two types of memory](https://langchain-ai.github.io/langgraph/how-tos/persistence/):\n",
    "\n",
    "1. **Short-term (within-thread) memory (a.k.a. checkpointers)**: Chatbot can persist conversational history and / or allow interruptions in a chat session \n",
    "2. **Long-term (cross-thread) memory (a.k.a. stores)**: Chatbot can remember information about a specific user *across all chat sessions*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
